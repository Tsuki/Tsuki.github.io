{"name":"Python","slug":"Python","count":2,"postlist":[{"title":"Python爬蟲","slug":"Python爬蟲","date":"2018-07-18T19:24:50.000Z","updated":"2018-07-18T12:49:24.377Z","comments":true,"path":"api/articles/Python爬蟲.json","excerpt":"","keywords":null,"cover":null,"content":"<p>簡易Python 爬蟲</p>\n<p>使用request提取網頁，再用bs4分析取得到html， 最後用urllib保存文件</p>\n<p>requests預設encoding很大機會是iso-8859-1</p>\n<p>所以在提取text之前需要修改成 <code>html.encoding = &#39;UTF-8&#39;</code></p>\n<p><code>range(1, int(numbers))</code> 是返會 <code>[1.....numbers-1]</code>  所以要使用 <code>range(1, int(numbers)+1)</code></p>\n<p>Python 沒有 <code>+=</code> 的寫法，合併Array只能 <code>array = array + [....]</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> bs4 <span class=\"keyword\">import</span> BeautifulSoup</span><br><span class=\"line\"><span class=\"keyword\">import</span> requests</span><br><span class=\"line\"><span class=\"keyword\">import</span> re</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> sys</span><br><span class=\"line\"><span class=\"keyword\">import</span> urllib.request</span><br><span class=\"line\"><span class=\"keyword\">from</span> tqdm <span class=\"keyword\">import</span> tqdm</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">author = <span class=\"string\">''</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">is_epub</span><span class=\"params\">(url)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"string\">'#epub'</span> <span class=\"keyword\">in</span> url[<span class=\"string\">'href'</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">main</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    booklist = []</span><br><span class=\"line\">    URL = <span class=\"string\">f\"https://tw.ixdzs.com/author/<span class=\"subst\">&#123;author&#125;</span>\"</span></span><br><span class=\"line\">    html = requests.get(URL)</span><br><span class=\"line\">    html.encoding = <span class=\"string\">'UTF-8'</span></span><br><span class=\"line\">    soup = BeautifulSoup(html.text, <span class=\"string\">'lxml'</span>)</span><br><span class=\"line\">    number = soup.find_all(<span class=\"string\">'a'</span>, title=<span class=\"string\">\"最後一頁\"</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\">    numbers = re.search(<span class=\"string\">r'page=(\\d+)$'</span>, number[<span class=\"string\">'href'</span>]).group(<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> num <span class=\"keyword\">in</span> list(range(<span class=\"number\">1</span>, int(numbers)+<span class=\"number\">1</span>)):</span><br><span class=\"line\">        URL = <span class=\"string\">f\"https://tw.ixdzs.com/author/<span class=\"subst\">&#123;author&#125;</span>?page=<span class=\"subst\">&#123;num&#125;</span>\"</span></span><br><span class=\"line\">        html = requests.get(URL)</span><br><span class=\"line\">        html.encoding = <span class=\"string\">'UTF-8'</span></span><br><span class=\"line\">        soup = BeautifulSoup(html.text, <span class=\"string\">'lxml'</span>)</span><br><span class=\"line\">        booklist = booklist + soup.find_all(<span class=\"string\">'a'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    urllist = filter(is_epub, booklist)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> os.path.exists(author):</span><br><span class=\"line\">        os.makedirs(author)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> url <span class=\"keyword\">in</span> tqdm(list(urllist)):</span><br><span class=\"line\">        book_id = re.search(<span class=\"string\">r'/d/\\d+/(\\d+)/#epub_down'</span>, url[<span class=\"string\">'href'</span>]).group(<span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">try</span>:</span><br><span class=\"line\">            title = re.search(<span class=\"string\">r'(.*)epub下載'</span>, url[<span class=\"string\">'title'</span>]).group(<span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">except</span> Exception:</span><br><span class=\"line\">            print(url[<span class=\"string\">'title'</span>])</span><br><span class=\"line\">            title = url[<span class=\"string\">'title'</span>]</span><br><span class=\"line\">        <span class=\"keyword\">if</span> os.path.exists(<span class=\"string\">f\"<span class=\"subst\">&#123;author&#125;</span>/<span class=\"subst\">&#123;title&#125;</span>.epub\"</span>):</span><br><span class=\"line\">            <span class=\"keyword\">continue</span></span><br><span class=\"line\">        urllib.request.urlretrieve(</span><br><span class=\"line\">            <span class=\"string\">f'https://tw.ixdzs.com/down/<span class=\"subst\">&#123;book_id&#125;</span>_4'</span>, <span class=\"string\">f'<span class=\"subst\">&#123;author&#125;</span>/<span class=\"subst\">&#123;title&#125;</span>.epub'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">\"__main__\"</span>:</span><br><span class=\"line\">    print(sys.argv)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> len(sys.argv) &lt; <span class=\"number\">2</span>:</span><br><span class=\"line\">        <span class=\"keyword\">raise</span> SyntaxError(<span class=\"string\">\"Insufficient arguments.\"</span>)</span><br><span class=\"line\">    author = sys.argv[<span class=\"number\">1</span>]</span><br><span class=\"line\">    main()</span><br></pre></td></tr></table></figure>\n","text":"簡易Python 爬蟲使用request提取網頁，再用bs4分析取得到html， 最後用urllib保存文件requests預設encoding很大機會是iso-8859-1所以在提取text之前需要修改成 html.encoding = &#39;UTF-8&#39;range","link":"","raw":null,"photos":["https://blog.sukitsuki.com/2018/07/18/Python爬蟲/photo_2018-07-09_10-59-23.jpg"],"categories":[{"name":"Python","slug":"Python","count":2,"path":"api/categories/Python.json"}],"tags":[]},{"title":"Python腳本調整歌詞開始位","slug":"lrc-offset","date":"2018-08-01T19:18:49.000Z","updated":"2018-08-18T13:01:30.765Z","comments":true,"path":"api/articles/lrc-offset.json","excerpt":"","keywords":null,"cover":null,"content":"<p>#一個 Python 腳本，用作全局調整歌詞提前量/開始位置</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\" data-line-number=\"1\"></span><br><span class=\"line\" data-line-number=\"2\"></span><br><span class=\"line\" data-line-number=\"3\"></span><br><span class=\"line\" data-line-number=\"4\"></span><br><span class=\"line\" data-line-number=\"5\"></span><br><span class=\"line\" data-line-number=\"6\"></span><br><span class=\"line\" data-line-number=\"7\"></span><br><span class=\"line\" data-line-number=\"8\"></span><br><span class=\"line\" data-line-number=\"9\"></span><br><span class=\"line\" data-line-number=\"10\"></span><br><span class=\"line\" data-line-number=\"11\"></span><br><span class=\"line\" data-line-number=\"12\"></span><br><span class=\"line\" data-line-number=\"13\"></span><br><span class=\"line\" data-line-number=\"14\"></span><br><span class=\"line\" data-line-number=\"15\"></span><br><span class=\"line\" data-line-number=\"16\"></span><br><span class=\"line\" data-line-number=\"17\"></span><br><span class=\"line\" data-line-number=\"18\"></span><br><span class=\"line\" data-line-number=\"19\"></span><br><span class=\"line\" data-line-number=\"20\"></span><br><span class=\"line\" data-line-number=\"21\"></span><br><span class=\"line\" data-line-number=\"22\"></span><br><span class=\"line\" data-line-number=\"23\"></span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> sys</span><br><span class=\"line\"><span class=\"keyword\">import</span> re</span><br><span class=\"line\"><span class=\"keyword\">from</span> datetime <span class=\"keyword\">import</span> date, datetime, time, timedelta</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">main</span><span class=\"params\">(filename: str, offset: int)</span> -&gt; <span class=\"keyword\">None</span>:</span></span><br><span class=\"line\">    thetime = re.compile(<span class=\"string\">r\"\\[([0-9]&#123;2&#125;):([0-9]&#123;2&#125;)\\.([0-9]&#123;2&#125;)?\\](.+)\"</span>)</span><br><span class=\"line\">    <span class=\"keyword\">with</span> open(filename, <span class=\"string\">'r+'</span>) <span class=\"keyword\">as</span> file:</span><br><span class=\"line\">        <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> file.readlines():</span><br><span class=\"line\">            min_sec_str = thetime.search(line)</span><br><span class=\"line\">            <span class=\"keyword\">if</span> min_sec_str:</span><br><span class=\"line\">                m, s, ms, lrc = min_sec_str.group(<span class=\"number\">1</span>), min_sec_str.group(<span class=\"number\">2</span>), min_sec_str.group(<span class=\"number\">3</span>), min_sec_str.group(<span class=\"number\">4</span>)</span><br><span class=\"line\">                t = datetime.combine(date.today(), time(<span class=\"number\">0</span>, int(m), int(s), int(ms))) + timedelta(milliseconds=offset)</span><br><span class=\"line\">                print(<span class=\"string\">f'[<span class=\"subst\">&#123;t.minute:<span class=\"number\">02</span>&#125;</span>:<span class=\"subst\">&#123;t.second:<span class=\"number\">02</span>&#125;</span>.<span class=\"subst\">&#123;t.microsecond:<span class=\"number\">02</span>&#125;</span>]<span class=\"subst\">&#123;lrc&#125;</span>'</span>)</span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                print(line)</span><br><span class=\"line\">    file.close</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">\"__main__\"</span>:</span><br><span class=\"line\">    <span class=\"keyword\">if</span> len(sys.argv) &lt; <span class=\"number\">3</span>:</span><br><span class=\"line\">        <span class=\"keyword\">raise</span> SyntaxError(<span class=\"string\">\"Insufficient arguments.\"</span>)</span><br><span class=\"line\">    main(sys.argv[<span class=\"number\">1</span>], int(sys.argv[<span class=\"number\">2</span>]))</span><br></pre></td></tr></table></figure>\n<p>先用正則找出歌詞位置，再提取出分，秒，微秒和歌詞，</p>\n<p>然後轉換成 Python 的時間類並調整時間，最後打印出來。</p>\n<h1 id=\"正則測試網站\"><a href=\"#正則測試網站\" class=\"headerlink\" title=\"正則測試網站\"></a>正則測試網站</h1><p><a href=\"https://regex101.com/\" target=\"_blank\" rel=\"noopener\">https://regex101.com/</a></p>\n","text":"#一個 Python 腳本，用作全局調整歌詞提前量/開始位置<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>import sys<br>impo","link":"","raw":null,"photos":["/2018/08/01/lrc-offset/photo_2018-07-03_21-21-15.jpg"],"categories":[{"name":"Python","slug":"Python","count":2,"path":"api/categories/Python.json"}],"tags":[]}]}