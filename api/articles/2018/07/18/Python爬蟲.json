{"title":"Python爬蟲","slug":"Python爬蟲","date":"2018-07-18T19:24:50.000Z","updated":"2018-07-18T12:49:24.377Z","comments":true,"path":"api/articles/2018/07/18/Python爬蟲.json","photos":["https://blog.sukitsuki.com/2018/07/18/Python爬蟲/photo_2018-07-09_10-59-23.jpg"],"link":"","excerpt":"","content":"<p>簡易Python 爬蟲</p>\n<p>使用request提取網頁，再用bs4分析取得到html， 最後用urllib保存文件</p>\n<p>requests預設encoding很大機會是iso-8859-1</p>\n<p>所以在提取text之前需要修改成 <code>html.encoding = &#39;UTF-8&#39;</code></p>\n<p><code>range(1, int(numbers))</code> 是返會 <code>[1.....numbers-1]</code>  所以要使用 <code>range(1, int(numbers)+1)</code></p>\n<p>Python 沒有 <code>+=</code> 的寫法，合併Array只能 <code>array = array + [....]</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> bs4 <span class=\"keyword\">import</span> BeautifulSoup</span><br><span class=\"line\"><span class=\"keyword\">import</span> requests</span><br><span class=\"line\"><span class=\"keyword\">import</span> re</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> sys</span><br><span class=\"line\"><span class=\"keyword\">import</span> urllib.request</span><br><span class=\"line\"><span class=\"keyword\">from</span> tqdm <span class=\"keyword\">import</span> tqdm</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">author = <span class=\"string\">''</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">is_epub</span><span class=\"params\">(url)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"string\">'#epub'</span> <span class=\"keyword\">in</span> url[<span class=\"string\">'href'</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">main</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    booklist = []</span><br><span class=\"line\">    URL = <span class=\"string\">f\"https://tw.ixdzs.com/author/<span class=\"subst\">&#123;author&#125;</span>\"</span></span><br><span class=\"line\">    html = requests.get(URL)</span><br><span class=\"line\">    html.encoding = <span class=\"string\">'UTF-8'</span></span><br><span class=\"line\">    soup = BeautifulSoup(html.text, <span class=\"string\">'lxml'</span>)</span><br><span class=\"line\">    number = soup.find_all(<span class=\"string\">'a'</span>, title=<span class=\"string\">\"最後一頁\"</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\">    numbers = re.search(<span class=\"string\">r'page=(\\d+)$'</span>, number[<span class=\"string\">'href'</span>]).group(<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> num <span class=\"keyword\">in</span> list(range(<span class=\"number\">1</span>, int(numbers)+<span class=\"number\">1</span>)):</span><br><span class=\"line\">        URL = <span class=\"string\">f\"https://tw.ixdzs.com/author/<span class=\"subst\">&#123;author&#125;</span>?page=<span class=\"subst\">&#123;num&#125;</span>\"</span></span><br><span class=\"line\">        html = requests.get(URL)</span><br><span class=\"line\">        html.encoding = <span class=\"string\">'UTF-8'</span></span><br><span class=\"line\">        soup = BeautifulSoup(html.text, <span class=\"string\">'lxml'</span>)</span><br><span class=\"line\">        booklist = booklist + soup.find_all(<span class=\"string\">'a'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    urllist = filter(is_epub, booklist)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> os.path.exists(author):</span><br><span class=\"line\">        os.makedirs(author)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> url <span class=\"keyword\">in</span> tqdm(list(urllist)):</span><br><span class=\"line\">        book_id = re.search(<span class=\"string\">r'/d/\\d+/(\\d+)/#epub_down'</span>, url[<span class=\"string\">'href'</span>]).group(<span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">try</span>:</span><br><span class=\"line\">            title = re.search(<span class=\"string\">r'(.*)epub下載'</span>, url[<span class=\"string\">'title'</span>]).group(<span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">except</span> Exception:</span><br><span class=\"line\">            print(url[<span class=\"string\">'title'</span>])</span><br><span class=\"line\">            title = url[<span class=\"string\">'title'</span>]</span><br><span class=\"line\">        <span class=\"keyword\">if</span> os.path.exists(<span class=\"string\">f\"<span class=\"subst\">&#123;author&#125;</span>/<span class=\"subst\">&#123;title&#125;</span>.epub\"</span>):</span><br><span class=\"line\">            <span class=\"keyword\">continue</span></span><br><span class=\"line\">        urllib.request.urlretrieve(</span><br><span class=\"line\">            <span class=\"string\">f'https://tw.ixdzs.com/down/<span class=\"subst\">&#123;book_id&#125;</span>_4'</span>, <span class=\"string\">f'<span class=\"subst\">&#123;author&#125;</span>/<span class=\"subst\">&#123;title&#125;</span>.epub'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">\"__main__\"</span>:</span><br><span class=\"line\">    print(sys.argv)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> len(sys.argv) &lt; <span class=\"number\">2</span>:</span><br><span class=\"line\">        <span class=\"keyword\">raise</span> SyntaxError(<span class=\"string\">\"Insufficient arguments.\"</span>)</span><br><span class=\"line\">    author = sys.argv[<span class=\"number\">1</span>]</span><br><span class=\"line\">    main()</span><br></pre></td></tr></table></figure>\n","prev":{"title":"ServerUpdate","link":"/2018/07/25/ServerUpdate"},"next":{"title":"Food","link":"/2018/07/18/Food"},"categories":[{"name":"Python","slug":"Python","count":2,"path":"api/categories/Python.json"}],"tags":[]}